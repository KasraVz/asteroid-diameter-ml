{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20408092",
   "metadata": {},
   "source": [
    "# Step 2 – Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b787370",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2-B Import libs & load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0827afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1436, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>...</th>\n",
       "      <th>UB</th>\n",
       "      <th>IR</th>\n",
       "      <th>spec_B</th>\n",
       "      <th>spec_T</th>\n",
       "      <th>G</th>\n",
       "      <th>moid</th>\n",
       "      <th>class</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.038918</td>\n",
       "      <td>0.069094</td>\n",
       "      <td>9.948162</td>\n",
       "      <td>217.408407</td>\n",
       "      <td>95.637570</td>\n",
       "      <td>2.828947</td>\n",
       "      <td>3.248890</td>\n",
       "      <td>5.297692</td>\n",
       "      <td>10333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83752</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.186048</td>\n",
       "      <td>1934.982100</td>\n",
       "      <td>226.241935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.781803</td>\n",
       "      <td>0.200606</td>\n",
       "      <td>9.233482</td>\n",
       "      <td>19.677473</td>\n",
       "      <td>164.054480</td>\n",
       "      <td>2.223758</td>\n",
       "      <td>3.339848</td>\n",
       "      <td>4.639784</td>\n",
       "      <td>7498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.22752</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.212429</td>\n",
       "      <td>1694.681031</td>\n",
       "      <td>97.864386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.532657</td>\n",
       "      <td>0.150951</td>\n",
       "      <td>7.307953</td>\n",
       "      <td>152.847672</td>\n",
       "      <td>256.627796</td>\n",
       "      <td>2.150350</td>\n",
       "      <td>2.914963</td>\n",
       "      <td>4.030627</td>\n",
       "      <td>10256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.17367</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.244534</td>\n",
       "      <td>1472.186639</td>\n",
       "      <td>135.680806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name         a         e         i          om           w         q  \\\n",
       "0  NaN  3.038918  0.069094  9.948162  217.408407   95.637570  2.828947   \n",
       "1  NaN  2.781803  0.200606  9.233482   19.677473  164.054480  2.223758   \n",
       "2  NaN  2.532657  0.150951  7.307953  152.847672  256.627796  2.150350   \n",
       "\n",
       "         ad     per_y  data_arc  ...  UB  IR  spec_B spec_T   G     moid  \\\n",
       "0  3.248890  5.297692   10333.0  ... NaN NaN     NaN    NaN NaN  1.83752   \n",
       "1  3.339848  4.639784    7498.0  ... NaN NaN     NaN    NaN NaN  1.22752   \n",
       "2  2.914963  4.030627   10256.0  ... NaN NaN     NaN    NaN NaN  1.17367   \n",
       "\n",
       "   class         n          per          ma  \n",
       "0    MBA  0.186048  1934.982100  226.241935  \n",
       "1    MBA  0.212429  1694.681031   97.864386  \n",
       "2    MBA  0.244534  1472.186639  135.680806  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA = Path(\"../data/asteroids_clean.csv\")   # file you saved in Step 1\n",
    "df = pd.read_csv(DATA)\n",
    "\n",
    "print(df.shape)     # expect (1436, 31)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b4148",
   "metadata": {},
   "source": [
    "**What we do**  \n",
    "1. Import pandas/NumPy.  \n",
    "2. Set a global random seed for reproducibility.  \n",
    "3. Load the cleaned CSV produced in Step 1.  \n",
    "\n",
    "**Why**  \n",
    "Everyone on the team starts from the same dataset and gets identical\n",
    "train/validation splits when we use `random_state=42`.\n",
    "\n",
    "*Expected output* → **(1436, 31)** rows × columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111b233",
   "metadata": {},
   "source": [
    "## 2-C Define target, drop junk, group columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f63cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = \"diameter\"\n",
    "\n",
    "DROP_ALWAYS = [\n",
    "    \"Unnamed: 0\",                 # ghost index (may already be absent)\n",
    "    \"GM\", \"G\", \"IR\", \"extent\",    # 100 % missing\n",
    "    \"UB\", \"BV\", \"spec_B\", \"spec_T\",  # > 99 % missing\n",
    "    \"name\"                        # mostly NaN and an arbitrary ID\n",
    "]\n",
    "\n",
    "X = df.drop(columns=[TARGET] + DROP_ALWAYS, errors=\"ignore\")\n",
    "y = df[TARGET]\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a097b0d",
   "metadata": {},
   "source": [
    "**What**  \n",
    "• Separate features `X` from the regression target `y`.  \n",
    "• Remove columns that cannot inform the model (all-missing or ID-like).\n",
    "\n",
    "**Why**  \n",
    "Dropping junk early keeps the pipeline lightweight and avoids leaking\n",
    "an identifier (`name`) that the model could memorise instead of learning\n",
    "real patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d20781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast condition_code (0–9 quality rating) to categorical\n",
    "X[\"condition_code\"] = X[\"condition_code\"].astype(\"object\")\n",
    "\n",
    "# per  = orbital period in days  |  per_y = same in years\n",
    "# Keep just one to avoid perfect collinearity\n",
    "X = X.drop(columns=[\"per_y\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323a856",
   "metadata": {},
   "source": [
    "**What**  \n",
    "1. `condition_code` is a *label* (0–9), not a quantity → treat it as a\n",
    "   category so the model gets one-hot dummies.  \n",
    "2. `per_y` duplicates `per`; we keep `per` (days) and drop the years\n",
    "   version.\n",
    "\n",
    "**Why**  \n",
    "Categorical coding prevents the model from interpreting “code 9” as\n",
    "nine times something.  Removing duplicate signals avoids redundant,\n",
    "perfectly correlated features that can mislead linear models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "491297bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 numeric  |  4 categorical\n",
      "Categoricals: ['condition_code', 'neo', 'pha', 'class']\n"
     ]
    }
   ],
   "source": [
    "NUMERIC_COLS     = X.select_dtypes([\"int64\", \"float64\"]).columns.tolist()\n",
    "CATEGORICAL_COLS = X.select_dtypes([\"object\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(f\"{len(NUMERIC_COLS)} numeric  |  {len(CATEGORICAL_COLS)} categorical\")\n",
    "print(\"Categoricals:\", CATEGORICAL_COLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e16d15",
   "metadata": {},
   "source": [
    "**What**  \n",
    "Ask pandas for two column lists: numeric and categorical.\n",
    "\n",
    "**Why**  \n",
    "These lists feed the ColumnTransformer so each branch (scaling vs\n",
    "one-hot) knows exactly which columns to handle.\n",
    "\n",
    "*Expected* → **17 numeric | 4 categorical**  \n",
    "(`neo`, `pha`, `class`, `condition_code`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc6ee6",
   "metadata": {},
   "source": [
    "## 2-D Build the column-wise pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4784f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\",  StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\", fill_value=\"Missing\")),\n",
    "    (\"encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, NUMERIC_COLS),\n",
    "    (\"cat\", categorical_pipe, CATEGORICAL_COLS)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b672cc9",
   "metadata": {},
   "source": [
    "**What**  \n",
    "*Numeric branch*  \n",
    "  • Impute NaNs with the **median** (robust to outliers).  \n",
    "  • Standard-scale to mean 0 / std 1.\n",
    "\n",
    "*Categorical branch*  \n",
    "  • Replace NaNs with the **most-frequent** label (or “Missing”).  \n",
    "  • One-hot encode; `handle_unknown=\"ignore\"` keeps the model alive when\n",
    "    it sees a brand-new category later.\n",
    "\n",
    "**Why**  \n",
    "Encapsulating every step in a Pipeline guarantees the exact same\n",
    "transforms are applied during cross-validation and on the real test\n",
    "data — eliminating data-leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4173213",
   "metadata": {},
   "source": [
    "## 2-E Train / validation split before fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097d42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1148, 20) (288, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a7deb",
   "metadata": {},
   "source": [
    "**What**  \n",
    "Reserve 20 % of the data for **validation**.\n",
    "\n",
    "**Why**  \n",
    "We must assess model quality on unseen data.  Splitting *before*\n",
    "calling `preprocess.fit()` ensures the imputer and scaler learn only\n",
    "from the training subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8fc8ad",
   "metadata": {},
   "source": [
    "## 2-F Fit the pipeline once to prove it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2548826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix → (1148, 39)\n",
      "Validation  → (288, 39)\n"
     ]
    }
   ],
   "source": [
    "preprocess.fit(X_train)\n",
    "\n",
    "X_train_ready = preprocess.transform(X_train)\n",
    "X_val_ready   = preprocess.transform(X_val)\n",
    "\n",
    "print(\"Train matrix →\", X_train_ready.shape)\n",
    "print(\"Validation  →\", X_val_ready.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286a6f2",
   "metadata": {},
   "source": [
    "**What**  \n",
    "• `.fit()` learns medians, most-frequent labels, scaling parameters, and\n",
    "  one-hot vocabularies **only from the training data**.  \n",
    "• `.transform()` converts raw rows into a pure-numeric matrix.\n",
    "\n",
    "**Why**  \n",
    "Checking the dimensions confirms all columns (plus one-hot expansions)\n",
    "are present and identical in train & validation matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db16f92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/preprocess.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocess, \"../data/preprocess.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82b4f6",
   "metadata": {},
   "source": [
    "Saving the fitted transformer lets teammates (or a deployment script)\n",
    "load it instantly:\n",
    "\n",
    "```python\n",
    "preprocess = joblib.load(\"../data/preprocess.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asteroid-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
