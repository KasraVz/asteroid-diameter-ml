{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c4e3a5",
   "metadata": {},
   "source": [
    "# Step 3 – Baseline models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b64e40",
   "metadata": {},
   "source": [
    "## 3A ― Imports & load essentials (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912bdb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA      = Path(\"../data/asteroids_clean.csv\")\n",
    "PREPROC_P = Path(\"../data/preprocess.pkl\")\n",
    "\n",
    "df         = pd.read_csv(DATA)\n",
    "preprocess = joblib.load(PREPROC_P)   # fitted transformer from Step 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069b578",
   "metadata": {},
   "source": [
    "**Purpose** Bring in scikit-learn, load the cleaned dataset, and load the\n",
    "already-fitted `preprocess.pkl` so every model sees the same transforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03a4fd",
   "metadata": {},
   "source": [
    "## 3B ― Recreate X and y (code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77daeab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"diameter\"\n",
    "\n",
    "DROP_ALWAYS = [\"Unnamed: 0\", \"GM\", \"G\", \"IR\", \"extent\",\n",
    "               \"UB\", \"BV\", \"spec_B\", \"spec_T\", \"name\",  # junk\n",
    "               \"per_y\"]                                 # duplicate of per\n",
    "\n",
    "X = df.drop(columns=[TARGET] + DROP_ALWAYS, errors=\"ignore\").copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Cast condition_code (0–9 quality label) to categorical\n",
    "X[\"condition_code\"] = X[\"condition_code\"].astype(\"object\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e5ca9",
   "metadata": {},
   "source": [
    "Mirror the exact column drops and type cast from Step 2 so the data\n",
    "arriving at `preprocess` has the layout it expects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13dc7f",
   "metadata": {},
   "source": [
    "## 3C ― Train / validation split (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81d1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7746b8",
   "metadata": {},
   "source": [
    "Hold out 20 % of rows as a validation set (identical random seed as\n",
    "before) so scores are comparable across all models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ca9c6",
   "metadata": {},
   "source": [
    "# Baseline 1 – DummyRegressor (median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b46376",
   "metadata": {},
   "source": [
    "## 3D ― Fit & predict (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391c97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = Pipeline([\n",
    "    (\"prep\", preprocess),                     # already fitted\n",
    "    (\"reg\",  DummyRegressor(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "dummy_model.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe8356",
   "metadata": {},
   "source": [
    "**Dummy (median)** simply predicts the training-set median for every\n",
    "asteroid.  This sets the absolute performance floor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062a348",
   "metadata": {},
   "source": [
    "## 3E ― Metrics (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1508514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 2.655770833333333,\n",
       " 'RMSE': 6.86362135647065,\n",
       " 'R²': -0.04744953304303601}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1️⃣  Try to import the new function (exists in sklearn ≥ 1.4)\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error  # noqa\n",
    "    def _rmse(y_true, y_pred):\n",
    "        return root_mean_squared_error(y_true, y_pred)\n",
    "except ImportError:\n",
    "    # 2️⃣  Fallback for older sklearn: manual sqrt of mean_squared_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    def _rmse(y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\":  mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": _rmse(y_true, y_pred),\n",
    "        \"R²\":   r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "scores_dummy = metrics(y_val, y_pred_dummy)\n",
    "scores_dummy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69f721",
   "metadata": {},
   "source": [
    "We record **MAE**, **RMSE** and **R²** for the naïve “predict‐the-median” model.  \n",
    "These values are the absolute floor: every real model must beat them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021bf77",
   "metadata": {},
   "source": [
    "## 3F ― Fit & predict with LinearRegression (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "407c620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = Pipeline([\n",
    "    (\"prep\", preprocess),          # reuse the fitted pre-processor\n",
    "    (\"reg\",  LinearRegression())\n",
    "])\n",
    "\n",
    "lin_model.fit(X_train, y_train)\n",
    "y_pred_lin = lin_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b1a27",
   "metadata": {},
   "source": [
    "A straight-line model in the engineered feature space.  \n",
    "Runs instantly and shows whether simple linear relationships capture real signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa237d",
   "metadata": {},
   "source": [
    "## 3G ― Metrics for the LinearRegression baseline (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5153e633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 2.226734298170547, 'RMSE': 9.30398774148489, 'R²': -0.9247074738179806}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-G — evaluate LinearRegression\n",
    "scores_lin = metrics(y_val, y_pred_lin)\n",
    "scores_lin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fff27a",
   "metadata": {},
   "source": [
    "If MAE and RMSE drop (and R² rises) compared with the Dummy baseline,\n",
    "we’ve proven even a basic linear model learns something meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ccb53",
   "metadata": {},
   "source": [
    "## 3H ― Side-by-side comparison table (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800d4e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy (median)</th>\n",
       "      <td>2.655771</td>\n",
       "      <td>6.863621</td>\n",
       "      <td>-0.047450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>2.226734</td>\n",
       "      <td>9.303988</td>\n",
       "      <td>-0.924707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MAE      RMSE        R²\n",
       "Dummy (median)    2.655771  6.863621 -0.047450\n",
       "LinearRegression  2.226734  9.303988 -0.924707"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-H — put both rows in one DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    [scores_dummy, scores_lin],\n",
    "    index=[\"Dummy (median)\", \"LinearRegression\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0be65",
   "metadata": {},
   "source": [
    "A single table makes it clear how much LinearRegression improves over the\n",
    "naïve baseline.  \n",
    "Future models (Random Forest, Gradient Boosting, …) will be added as extra rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efbaf3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: could not open directory 'notebooks/notebooks/': No such file or directory\n",
      "fatal: pathspec 'notebooks/03_baselines.ipynb' did not match any files\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   02_preprocessing.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m../data/data.csv\u001b[m\n",
      "\t\u001b[31m03_baselines.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add notebooks/03_baselines.ipynb\n",
    "!git commit -m \"Step 3: evaluated Dummy & Linear baselines\"\n",
    "!git push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988f209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asteroid-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
